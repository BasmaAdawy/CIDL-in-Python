{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Radial Basis Function Network (RBF) for Regression**\n",
        "\n",
        "This notebook demonstrates the implementation of a Radial Basis Function (RBF) network for regression tasks. It covers data generation, the core RBF network architecture, training methodology, and performance evaluation."
      ],
      "metadata": {
        "id": "intro_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "setup_code",
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Synthetic Data Generation**\n",
        "\n",
        "Here, we'll generate our synthetic dataset using a mixture of Gaussian functions. This 1D dataset will serve as the target for our RBF regression model."
      ],
      "metadata": {
        "id": "synthetic_data_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mog1D_gen(Npatterns=200, visualize=True):\n",
        "    \"\"\"\n",
        "    Generates a 1D Mixture of Gaussians synthetic dataset\n",
        "\n",
        "    Parameters:\n",
        "    - Npatterns: Number of data points to generate\n",
        "    - visualize: Whether to plot the generated data\n",
        "\n",
        "    Returns:\n",
        "    - X: Input features (Npatterns x 1)\n",
        "    - y: Target values (Npatterns x 1)\n",
        "    \"\"\"\n",
        "    X = np.linspace(-10, 10, Npatterns).reshape(-1, 1)\n",
        "\n",
        "    # Define parameters for three Gaussian kernels\n",
        "    centre1, centre2, centre3 = -8, -1, 7\n",
        "    ampl1, ampl2, ampl3 = 3, -5, 9\n",
        "    epsilon = 0.3\n",
        "\n",
        "    # Compute each kernel component\n",
        "    k1 = ampl1 * np.exp(-((X - centre1) * epsilon)**2)\n",
        "    k2 = ampl2 * np.exp(-((X - centre2) * epsilon)**2)\n",
        "    k3 = ampl3 * np.exp(-((X - centre3) * epsilon)**2)\n",
        "\n",
        "    # Combine kernels to form target output\n",
        "    y = k1 + k2 + k3\n",
        "\n",
        "    if visualize:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(X, k1, 'ob', label=f'kernel 1 (centre={centre1}, amplitude={ampl1})')\n",
        "        plt.plot(X, k2, 'sr', label=f'kernel 2 (centre={centre2}, amplitude={ampl2})')\n",
        "        plt.plot(X, k3, '^g', label=f'kernel 3 (centre={centre3}, amplitude={ampl3})')\n",
        "        plt.plot(X, y, '.k', label='Combined output y')\n",
        "        plt.legend(fontsize=12)\n",
        "        plt.title('1D Mixture of Gaussians Synthetic Dataset', fontsize=14)\n",
        "        plt.xlabel('Input X', fontsize=12)\n",
        "        plt.ylabel('Output y', fontsize=12)\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "mog1d_gen_code",
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. RBF Network Core Functions**\n",
        "\n",
        "This section defines the fundamental building blocks of our RBF network, including functions for extending input with a bias term, performing the forward pass, initializing RBF centers, training the network weights offline, and making predictions."
      ],
      "metadata": {
        "id": "rbf_core_functions_markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1 Key Formulas**\n",
        "\n",
        "The RBF network relies on two primary formulas:\n",
        "\n",
        "### **Gaussian Radial Basis Function**\n",
        "This function measures the similarity between an input vector $\\mathbf{x}$ and a center vector $\\mathbf{c}$, modulated by a width parameter $\\epsilon$:\n",
        "$$\\phi(\\mathbf{x}, \\mathbf{c}, \\epsilon) = e^{-\\epsilon^2 \\|\\mathbf{x} - \\mathbf{c}\\|^2}$$\n",
        "where:\n",
        "* $\\mathbf{x}$ is the input vector.\n",
        "* $\\mathbf{c}$ is the center of the radial basis function.\n",
        "* $\\epsilon$ is the width parameter (also known as inverse radius).\n",
        "* $\\|\\cdot\\|$ denotes the Euclidean norm.\n",
        "\n",
        "### **Network Output (Linear Output Layer)**\n",
        "The final output of the RBF network is a linear combination of the outputs from the hidden layer RBF units and a bias term:\n",
        "$$\\hat{y} = \\sum_{i=1}^{N_H} w_i \\phi_i(\\mathbf{x}) + w_0$$\n",
        "where:\n",
        "* $\\hat{y}$ is the predicted output.\n",
        "* $N_H$ is the number of hidden units (RBF centers).\n",
        "* $w_i$ are the weights connecting the $i$-th hidden unit to the output.\n",
        "* $\\phi_i(\\mathbf{x})$ is the output of the $i$-th RBF unit for input $\\mathbf{x}$.\n",
        "* $w_0$ is the bias weight."
      ],
      "metadata": {
        "id": "rbf_formulas_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RBF_extend(X):\n",
        "    \"\"\"\n",
        "    Extends the input matrix by adding a row of ones (bias term)\n",
        "\n",
        "    Parameters:\n",
        "    - X: Input matrix (n_features x n_samples)\n",
        "\n",
        "    Returns:\n",
        "    - Extended matrix with bias term ((n_features+1) x n_samples)\n",
        "    \"\"\"\n",
        "    return np.vstack([np.ones(X.shape[1]), X])\n"
      ],
      "metadata": {
        "id": "rbf_extend_code",
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RBF_forward(P, W1, W2, epsilon):\n",
        "    \"\"\"\n",
        "    Forward pass of the RBF network\n",
        "\n",
        "    Parameters:\n",
        "    - P: Input patterns (n_samples x n_features)\n",
        "    - W1: Centers matrix (n_hidden x n_features)\n",
        "    - W2: Output weights (1 x (n_hidden+1))\n",
        "    - epsilon: Width parameter for Gaussian RBFs\n",
        "\n",
        "    Returns:\n",
        "    - rA2: Network output (1 x n_samples)\n",
        "    - A1: Extended hidden layer outputs ((n_hidden+1) x n_samples)\n",
        "    \"\"\"\n",
        "    rA0 = P.T  # Transpose input matrix (D x B)\n",
        "    # Compute Euclidean distances between each pattern and each center\n",
        "    rZ1 = np.sqrt(np.sum((W1[:, :, np.newaxis] - rA0[np.newaxis, :, :])**2, axis=1))\n",
        "    # Apply Gaussian activation function\n",
        "    rA1 = np.exp(-(epsilon**2 * (rZ1**2)))\n",
        "    # Extend hidden layer outputs with bias term\n",
        "    A1 = RBF_extend(rA1)\n",
        "    # Compute output layer pre-activation\n",
        "    rZ2 = W2 @ A1\n",
        "    # Output (linear activation)\n",
        "    rA2 = rZ2\n",
        "\n",
        "    return rA2, A1"
      ],
      "metadata": {
        "id": "rbf_forward_code",
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RBF_initialize_centres(model, Xtrain, ytrain):\n",
        "    \"\"\"\n",
        "    Initializes the RBF centers based on the specified method\n",
        "\n",
        "    Parameters:\n",
        "    - model: Dictionary containing model parameters\n",
        "    - Xtrain: Training inputs (n_samples x n_features)\n",
        "    - ytrain: Training targets (n_samples x 1)\n",
        "\n",
        "    Returns:\n",
        "    - model: Updated model dictionary\n",
        "    - W1: Centers matrix (n_hidden x n_features)\n",
        "    \"\"\"\n",
        "    method = model['centres_generation_method']\n",
        "    n_hidden = model['n_hidden']\n",
        "\n",
        "    if method == 'random':\n",
        "        # Randomly select training points as centers\n",
        "        idx = np.random.permutation(Xtrain.shape[0])\n",
        "        W1 = Xtrain[idx[:n_hidden], :]\n",
        "    elif method == 'clustering':\n",
        "        # K-means clustering for center initialization\n",
        "        from sklearn.cluster import KMeans\n",
        "        kmeans = KMeans(n_clusters=n_hidden, max_iter=50, tol=0.001, random_state=42) # Added random_state for reproducibility\n",
        "        print('Clustering training data using K-means...')\n",
        "        kmeans.fit(Xtrain)\n",
        "        W1 = kmeans.cluster_centers_\n",
        "        print('Clustering completed - centers initialized')\n",
        "    elif method == 'debug':\n",
        "        # Fixed centers for debugging\n",
        "        if n_hidden != 3:\n",
        "            print('Warning: Forcing n_hidden=3 for debug mode')\n",
        "            model['n_hidden'] = 3\n",
        "            n_hidden = 3\n",
        "\n",
        "        if Xtrain.shape[1] == 1:\n",
        "            W1 = np.array([[-8], [-1], [7]])\n",
        "        elif Xtrain.shape[1] == 2:\n",
        "            W1 = np.array([[-8, -8], [-1, -1], [7, 7]])\n",
        "        else:\n",
        "            raise ValueError('Unsupported input dimension for debug mode')\n",
        "    else:\n",
        "        raise ValueError('Unrecognized center generation method')\n",
        "\n",
        "    model['W1'] = W1\n",
        "    return model, W1"
      ],
      "metadata": {
        "id": "rbf_initialize_centres_code",
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RBF_train_offline(X, y, model):\n",
        "    \"\"\"\n",
        "    Trains the RBF network in two phases:\n",
        "    1. Center initialization\n",
        "    2. Output weight computation via least squares\n",
        "\n",
        "    Parameters:\n",
        "    - X: Training inputs (n_samples x n_features)\n",
        "    - y: Training targets (n_samples x 1)\n",
        "    - model: Model configuration dictionary\n",
        "\n",
        "    Returns:\n",
        "    - model: Updated model with trained parameters\n",
        "    - W1: Centers matrix (n_hidden x n_features)\n",
        "    - W2: Output weights (1 x (n_hidden+1))\n",
        "    \"\"\"\n",
        "    # Phase 1: Center initialization\n",
        "    model, W1 = RBF_initialize_centres(model, X, y)\n",
        "\n",
        "    # Phase 2: Compute output weights via least squares\n",
        "    # Forward pass to get hidden layer outputs\n",
        "    _, A1 = RBF_forward(X, W1, np.ones((1, model['n_hidden'] + 1)), model['epsilon'])\n",
        "\n",
        "    # Reshape y to match expected dimensions (n_samples,) instead of (n_samples, 1)\n",
        "    y_flat = y.ravel()\n",
        "\n",
        "    # Solve least squares problem for output weights\n",
        "    W2 = np.linalg.lstsq(A1.T, y_flat, rcond=None)[0]\n",
        "    W2 = W2.reshape(1, -1)  # Ensure W2 is (1 x (n_hidden+1))\n",
        "\n",
        "    model['W2'] = W2\n",
        "    return model, W1, W2\n"
      ],
      "metadata": {
        "id": "rbf_train_offline_code",
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RBF_predict(X, W1, W2, epsilon):\n",
        "    \"\"\"\n",
        "    Makes predictions using the trained RBF network\n",
        "\n",
        "    Parameters:\n",
        "    - X: Input patterns (n_samples x n_features)\n",
        "    - W1: Centers matrix (n_hidden x n_features)\n",
        "    - W2: Output weights (1 x (n_hidden+1))\n",
        "    - epsilon: Width parameter for Gaussian RBFs\n",
        "\n",
        "    Returns:\n",
        "    - Predictions (1 x n_samples)\n",
        "    \"\"\"\n",
        "    y_pred, _ = RBF_forward(X, W1, W2, epsilon)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "rbf_predict_code",
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Main Script: Data Generation, Model Configuration, Training, and Evaluation**\n",
        "\n",
        "This section integrates all the defined functions to generate the dataset, configure the RBF model, train it, and then evaluate its performance on both training and test sets. Visualizations of predictions and performance metrics are included."
      ],
      "metadata": {
        "id": "main_script_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Generate training and test data\n",
        "Ntrain = 300\n",
        "Ntest = 200\n",
        "Xtrain, ytrain = mog1D_gen(Ntrain, True)\n",
        "Xtest, ytest = mog1D_gen(Ntest, False)\n"
      ],
      "metadata": {
        "id": "data_generation_code",
        "collapsed": true,
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model parameters\n",
        "model = {\n",
        "    'n_output': 1,              # Single output regression\n",
        "    'n_features': 1,            # 1D input\n",
        "    'n_hidden': 30,             # Number of RBF centers\n",
        "    'epsilon': 0.3,             # RBF width parameter\n",
        "    'centres_generation_method': 'clustering'  # Center initialization method\n",
        "    # Alternatives: 'random', 'debug'\n",
        "}"
      ],
      "metadata": {
        "id": "model_config_code",
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the RBF network\n",
        "print(\"\\nStarting RBF network training...\")\n",
        "model, W1, W2 = RBF_train_offline(Xtrain, ytrain, model)\n",
        "print(\"RBF network training complete.\")\n"
      ],
      "metadata": {
        "id": "model_training_code",
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "ytrain_pred = RBF_predict(Xtrain, W1, W2, model['epsilon'])\n",
        "ytest_pred = RBF_predict(Xtest, W1, W2, model['epsilon'])\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(Xtrain, ytrain, '.b', label='True values')\n",
        "plt.plot(Xtrain, ytrain_pred.T, 'or', label='Predictions', alpha=0.5)\n",
        "plt.legend(fontsize=12)\n",
        "plt.title('RBF Network Predictions vs True Values (Training Set)', fontsize=14)\n",
        "plt.xlabel('Input X', fontsize=12)\n",
        "plt.ylabel('Output y', fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Scatter plots of true vs predicted values\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(ytrain, ytrain_pred.T, '.b')\n",
        "plt.title('Training Set Predictions', fontsize=12)\n",
        "plt.xlabel('True y', fontsize=10)\n",
        "plt.ylabel('Predicted y', fontsize=10)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(ytest, ytest_pred.T, '.r')\n",
        "plt.title('Test Set Predictions', fontsize=12)\n",
        "plt.xlabel('True y', fontsize=10)\n",
        "plt.ylabel('Predicted y', fontsize=10)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "prediction_visualization_code",
        "execution_count": null,
        "outputs": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE\n",
        "mse_train = np.mean((ytrain.T - ytrain_pred)**2)\n",
        "mse_test = np.mean((ytest.T - ytest_pred)**2)\n",
        "\n",
        "print(f'Training MSE: {mse_train:.4f}')\n",
        "print(f'Test MSE: {mse_test:.4f}')"
      ],
      "metadata": {
        "id": "performance_metrics_code",
        "execution_count": null,
        "outputs": []
      }
    }
  ]
}
